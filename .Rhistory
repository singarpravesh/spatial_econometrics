sess %>% html_elements("#__next > div.HorizontalDefaultLayout_contentWrapper__RvzTK > div > div > div.TopColleges2023_tableBlock__2cW2s > div.TopColleges2023_tableWrapper__o3tS1 > div.TopColleges2023_table__4hfbE") %>% html_text2()
sess <- read_html("https://www.forbes.com/top-colleges/")
sess %>% html_element("table")
sess %>% html_elements("table")
sess %>% html_elements(".table")
sess %>% html_elements("#__next > div.HorizontalDefaultLayout_contentWrapper__RvzTK > div > div > div.TopColleges2023_tableBlock__2cW2s > div.TopColleges2023_tableWrapper__o3tS1 > div.TopColleges2023_table__4hfbE")
sess %>% html_elements("role")
sess %>% html_elements("#princeton-university")
sess %>% html_elements("#princeton-university")
sess %>% html_element("#princeton-university")
sess %>% html_nodes("#princeton-university")
sess %>% html_nodes(".princeton-university")
sess %>% html_elements(".princeton-university")
sess %>% html_elements("class")
sess %>% html_elements("TopColleges2023_tableBlock__2cW2s")
sess %>% html_elements(".TopColleges2023_tableBlock__2cW2s")
sess %>% html_elements("TopColleges2023_rank__6vFzI")
web <- read_html("https://theordinary.com/en-de/100-plant-derived-squalane-face-oil-100398.html")
web %>% html_elements("h1.product-name")
web %>% html_elements("h1.product-name") %>% html_text()
# Send a GET request to the URL
page <- read_html("https://www.99acres.com/search/property/buy/kolkata?city=25&keyword=kolkata&preference=S&area_unit=1&res_com=R")
# Send a GET request to the URL
page <- read_html_live("https://www.99acres.com/search/property/buy/kolkata?city=25&keyword=kolkata&preference=S&area_unit=1&res_com=R")
page %>%  html_elements("section")
page %>%  html_elements("section") %>%  html_text()
page %>%  html_elements("<div class="tupleNew__locationName ellipsis">Action Area 3, Kolkata East</div>") %>%  html_text()
page %>%  html_elements("<div class="tupleNew__locationName.ellipsis">Action Area 3, Kolkata East</div>") %>%  html_text()
page %>%  html_elements("#O75779403 > div > div.tupleNew__innerCont > div.tupleNew__contentWrap > div.tupleNew__subWrapper > div > div.tupleNew__headingCont > div.tupleNew__headingNrera > div") %>%  html_text()
page %>%  html_elements("div.tupleNew__locationName ellipsis") %>%  html_text()
page %>%  html_elements("div.tupleNew__locationName.ellipsis") %>%  html_text()
page %>%  html_elements("div.tupleNew__locationName.ellipsis") %>%  html_text2()
page %>%  html_elements("div.tupleNew__headingNrera") %>%  html_text2()
page %>%  html_elements("div.tupleNew__tupleHeading") %>%  html_text2()
page %>%  html_elements("div.tupleNew__tupleHeading") %>%  html_text()
page %>%  htmnl_elements("section") %>%
html_elements("div.tupleNew__tupleHeading") %>%  html_text()
page %>%  html_elements("section") %>%
html_elements("div.tupleNew__tupleHeading") %>%  html_text()
page %>%  html_elements("section")
page %>%  html_elements("section") %>%
html_elements("class")
page %>%  html_elements("section") %>%
html_elements("div")
page %>%  html_elements("section") %>%
html_elements("div. pageComponent undefined")
page %>%  html_elements("section") %>%
html_elements("div. pageComponent.undefined")
page %>%  html_elements("section") %>%
html_elements("div.pageComponent.undefined")
page %>%  html_elements("section") %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section")
page %>%  html_elements("section") %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section.data-hydration-on-demand="true"")
page %>%  html_elements("section") %>%
html_elements("div.pageComponent.undefined")[1]
page %>%  html_elements("section") %>%
html_elements("div.pageComponent.undefined")[[1]]
page %>%  html_elements("section") %>%
html_elements("div.pageComponent.undefined") %>% html_text()
page %>%
html_elements("div.pageComponent.undefined") %>% html_text()
page %>%
html_elements("div.pageComponent.undefined")
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section.data-hydration-on-demand="true"")
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section")
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section")
html_elements("div#tupleNew__outerTupleWrap")
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section")
html_elements("div#O75779403,tupleNew__outerTupleWrap")
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section")
html_elements("div.tupleNew__tupleWrap.tupleNew__PremH")
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_elements("div#O75779403,tupleNew__outerTupleWrap")
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_elements("div#O75779403.tupleNew__outerTupleWrap")
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_elements("div.tupleNew__locationName.ellipsis")
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_elements("div.tupleNew__locationName.ellipsis") %>%  html_text()
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_elements("div.tupleNew__locationName.ellipsis") %>%
html_elements("div.tupleNew__propertyHeading.ellipsis") %>% html_text()
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_elements("div.tupleNew__propertyHeading.ellipsis") %>% html_text()
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_elements("div.tupleNew__propertyHeading.ellipsis")
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_elements("h2.tupleNew__propType") %>% html_text()
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_elements("h2.tupleNew__propType") %>%
html_element("text")
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_elements("h2.tupleNew__propType") %>%
html_element("#text")
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_element("#text")
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_element("#text")
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_elements("h2")  %>% html_text()
locations <- page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_elements("h2")  %>% html_text()
locations
page %>%
html_elements("div.tupleNew__perSqftWrap.ellipsis")
page %>%
html_elements("div.tupleNew__priceValWrap")
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_elements("div.tupleNew__priceValWrap")
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_elements("div.tupleNew__priceValWrap") %>%  html_text()
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_elements("span") %>%  html_text()
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_elements("div.tupleNew__priceValWrap") %>%
html_elements("span")
page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_elements("div.tupleNew__priceAreaWrap") %>%
html_elements("span")
%>%
page %>%
html_elements("div")
page %>%
html_elements("div")
page %>%
html_elements("div") %>%
html_elements("section")
page %>%
html_elements("div") %>%
html_elements("section") %>%
html_elements("div")
page %>%
html_elements("div") %>%
html_elements("section") %>%
html_elements("div") %>%
html_elements("h2")
html_elements("span")
page %>%
html_elements("div") %>%
html_elements("section") %>%
html_elements("div") %>%
html_elements("h2") %>%
html_elements("span")
# Load the necessary libraries
library(rvest)
library(dplyr)
# Send a GET request to the URL
page <- read_html_live("https://www.99acres.com/search/property/buy/kolkata?city=25&keyword=kolkata&preference=S&area_unit=1&res_com=R")
# Load the necessary libraries
library(rvest)
library(dplyr)
# Send a GET request to the URL
page <- read_html_live("https://www.99acres.com/search/property/buy/kolkata?city=25&keyword=kolkata&preference=S&area_unit=1&res_com=R")
# Load the necessary libraries
library(rvest)
# Send a GET request to the URL
page <- read_html_live("https://www.99acres.com/search/property/buy/kolkata?city=25&keyword=kolkata&preference=S&area_unit=1&res_com=R")
?read_html_live
library(rvest)
??rvest
rvest
install.packages("rvest")
install.packages("rvest")
# Load the necessary libraries
library(rvest)
library(dplyr)
# Send a GET request to the URL
page <- read_html_live("https://www.99acres.com/search/property/buy/kolkata?city=25&keyword=kolkata&preference=S&area_unit=1&res_com=R")
# Send a GET request to the URL
page <- read_html_live("https://www.99acres.com/search/property/buy/kolkata?city=25&keyword=kolkata&preference=S&area_unit=1&res_com=R")
locations <- page %>%
html_elements("div.pageComponent.undefined") %>%
html_elements("section") %>%
html_elements("h2")  %>% html_text()
page %>%
html_elements("div") %>%
html_elements("section") %>%
html_elements("div") %>%
html_elements("h2") %>%
html_elements("span")
page %>%
html_elements("div")
install.packages(RSelinium)
install.packages('RSelinium')
install.packages('netstat')
library(tidyverse) # for data wrangling
library(RSelenium) # activate Selenium server
install.packages("RSelenium")
library(RSelenium) # activate Selenium server
library(netstat) # find unused port
library(rvest) # web scrape tables
library(data.table) # for the rbindlist function
rs_driver_object <- rsDriver('chrome')
rs_driver_object <- rsDriver(browser = 'chrome')
sessionInfo()
rs_driver_object <- rsDriver(browser = 'chrome')
library(tidyverse) # for data wrangling
library(RSelenium) # activate Selenium server
library(netstat) # find unused port
library(rvest) # web scrape tables
library(data.table) # for the rbindlist function
rs_driver_object <- rsDriver(browser = 'chrome')
Sys.setenv(JAVA_HOME="C:/Program Files/Java/")
rs_driver_object <- rsDriver(browser = 'chrome')
Sys.setenv(JAVA_HOME="C:/Program Files/Java/jdk-22")
rs_driver_object <- rsDriver(browser = 'chrome')
Sys.setenv(JAVA_HOME="C:/Program Files/Java/jdk-22/")
rs_driver_object <- rsDriver(browser = 'chrome')
library(tidyverse) # for data wrangling
library(RSelenium) # activate Selenium server
library(netstat) # find unused port
library(rvest) # web scrape tables
library(data.table) # for the rbindlist function
rs_driver_object <- rsDriver(browser = 'chrome')
java_check()
library(tidyverse) # for data wrangling
library(RSelenium) # activate Selenium server
library(netstat) # find unused port
library(rvest) # web scrape tables
library(data.table) # for the rbindlist function
rs_driver_object <- rsDriver(browser = 'chrome')
binman::list_versions("chromedriver")
binman::list_versions("chromedriver")
rs_driver_object <- rsDriver(browser = 'chrome',
chromever = "126.0.6478.61",
verbose = F,
port = free_port())
rs_driver_object <- rsDriver(browser = 'chrome',
chromever = "114.0.5735.90",
verbose = F,
port = free_port())
library(tidyverse) # for data wrangling
library(RSelenium) # activate Selenium server
library(netstat) # find unused port
library(rvest) # web scrape tables
library(data.table) # for the rbindlist function
binman::list_versions("chromedriver")
binman::list_versions("chromedriver")$win64
binman::list_versions("chromedriver")
library(tidyverse) # for data wrangling
library(RSelenium) # activate Selenium server
library(netstat) # find unused port
library(rvest) # web scrape tables
library(data.table) # for the rbindlist function
binman::list_versions("chromedriver")
?binman::list_versions()
binman::list_versions("chromedriver", platform = "win64")
rs_driver_object <- rsDriver(browser = 'chrome',
chromever = "126.0.6478.62",
verbose = F, # verbose = F to suppress any messages
port = free_port()) # free_port() to find a free port to run the Selenium server
?rsDriver
rs_driver_object <- rsDriver(browser = 'chrome',
chromever = "latest",
verbose = F, # verbose = F to suppress any messages
port = free_port()) # free_port() to find a free port to run the Selenium server
rs_driver_object <- rsDriver(browser = 'firefox',
verbose = F, # verbose = F to suppress any messages
port = free_port()) # free_port() to find a free port to run the Selenium server
binman::list_versions("firefox")
rs_driver_object <- rsDriver(browser = 'chrome',
verbose = F, # verbose = F to suppress any messages
port = free_port()) # free_port() to find a free port to run the Selenium server
rs_driver_object <- rsDriver(browser = 'chrome',
verbose = F, # verbose = F to suppress any messages
port = free_port()) # free_port() to find a free port to run the Selenium server
rs_driver_object <- rsDriver(browser = 'chrome',
verbose = F) # verbose = F to suppress any messages
rs_driver_object <- rsDriver(browser = 'firefox',
verbose = F) # verbose = F to suppress any messages
library(tidyverse) # for data wrangling
library(RSelenium) # activate Selenium server
library(netstat) # find unused port
library(rvest) # web scrape tables
library(data.table) # for the rbindlist function
binman::list_versions("chromedriver")
rs_driver_object <- rsDriver(browser = 'chrome',
chromever = "114.0.5735.90",
verbose = F, # verbose = F to suppress any messages
port = free_port())
rs_driver_object <- rsDriver(browser = "chrome",
chromever = "114.0.5735.90",
verbose = F, # verbose = F to suppress any messages
port = free_port())
rs_driver_object <- rsDriver(browser = "chrome",
chromever = "114.0.5735.90")
rs_driver_object <- rsDriver(browser = "chrome",
chromever = "114.0.5735.90")
rs_driver_object <- rsDriver(browser = "chrome",
chromever = "114.0.5735.90",
check = "TRUE")
rs_driver_object <- rsDriver(browser = "chrome",
chromever = "114.0.5735.90",
port = "netstat::free_port()")
rs_driver_object <- rsDriver(browser = "chrome",
chromever = "114.0.5735.90",
port = netstat::free_port())
rs_driver_object <- rsDriver(browser = "chrome",
chromever = "114.0.5735.90",
port = 14416)
rs_driver_object <- rsDriver(browser = "chrome",
chromever = "114.0.5735.90",
port = 14416L)
rsDriver(browser = "chrome",
chromever = "114.0.5735.90",
chromepath = "C:\Users\Pravesh\Downloads\chromedriver_win32\chromedriver.exe")
rsDriver(browser = "chrome",
chromever = "114.0.5735.90",
chromepath = "C:\\Users\\Pravesh\\Downloads\\chromedriver_win32\\chromedriver.exe")
rs_driver_object <- rsDriver(browser = "chrome",
chromever = "114.0.5735.90",
check = F)
rs_driver_object <- rsDriver(browser = "chrome",
chromever = "114.0.5735.90",
port = 9515)
rs_driver_object <- rsDriver(browser = "chrome",
chromever = "114.0.5735.90",
port = 9515L)
rs_driver_object$client
rs_driver_object$client
remDr <- rs_driver_object$client
remDr$open
remDr$navigate("https://www.99acres.com/search/property/buy/kolkata?city=25&preference=S&area_unit=1&res_com=R")
library(tidyverse) # for data wrangling
library(RSelenium) # activate Selenium server
library(netstat) # find unused port
library(rvest) # web scrape tables
library(data.table) # for the rbindlist function
rs_driver_object <- rsDriver(browser = "chrome")
library(tidyverse) # for data wrangling
install.packages(c("tidyverse", "RSelenium", "netstat", "rvest", "data.table"))
library(tidyverse) # for data wrangling
library(RSelenium) # activate Selenium server
library(netstat) # find unused port
library(rvest) # web scrape tables
library(data.table) # for the rbindlist function
rs_driver_object <- rsDriver(browser = "chrome",
chromever = "114.0.5735.90",
port = 9515L)
# Load the necessary libraries
library(rvest)
library(dplyr)
# Define the URL for the property listings
url <- "file:///C:/Users/Pravesh/Downloads/Property%20in%20Kolkata%20-%20Real%20Estate%20in%20Kolkata.html"
# Send a GET request to the URL
page <- read_html(url)
# Define the URL for the property listings
url <- "Property in Kolkata - Real Estate in Kolkata.html"
# Send a GET request to the URL
page <- read_html(url)
page %>%
html_elements("div.configs_ccl2")
page %>%
html_elements("section") |>
html_elements("div.configs_ccl2")
page %>%
html_elements("section")
page %>%
html_elements("section") |>
html_elements("div")
page %>%
html_elements("section") |>
html_elements("div") |>
html_elements("div.configs_ccl2")
page %>%
html_elements("section") |>
html_elements("div") |>
html_elements("div")
page %>%
html_elements("section") |>
html_elements("div") |>
html_elements("div") |>
html_elements("div.configs_ccl2")
page %>%
html_elements("section")
locations <- page %>%
html_elements("section") |> html_table()
locations <- page %>%
html_elements("section") |> html_table("section")
# Send a GET request to the URL
page <- read_html("https://www.99acres.com/property-in-kolkata-ffid-page-1")
# Load the necessary libraries
library(rvest)
library(dplyr)
# Send a GET request to the URL
page <- read_html("https://www.99acres.com/property-in-kolkata-ffid-page-1")
binman::list_versions("chromedriver")
#install.packages('devtools')
#devtools::install_github('ropensci/rdhs')
library(rdhs)
library(tidyverse)
install.packages(c("AER", "backports", "bitops", "broom", "bslib", "caTools", "chromote", "cli", "colorspace", "curl", "data.table", "digest", "duckdb", "future", "gmp", "httr2", "knitr", "lme4", "minqa", "multcomp", "mvtnorm", "nloptr", "parallelly", "pbkrtest", "pkgload", "polyclip", "ps", "quantreg", "ragg", "Rcpp", "RcppArmadillo", "RcppEigen", "RcppSimdJson", "reprex", "rlang", "rmarkdown", "shiny", "SparseM", "spatialreg", "spatstat.geom", "spatstat.utils", "spData", "spdep", "stars", "stringi", "systemfonts", "testthat", "textshaping", "tinytex", "uuid", "waldo", "websocket", "xfun", "XML", "yaml"))
kr_data
#install.packages('devtools')
#devtools::install_github('ropensci/rdhs')
library(rdhs)
library(tidyverse)
# set your credentials
set_rdhs_config(email = "pravesh.econ@presiuniv.ac.in",
project = "ecological study of health")
kr
# download datasets
kr <- get_datasets(datasets$FileName[7] )
# dhs datasets
dhs_datasets(countryIds = "IA",
surveyYearStart = 2020, fileFormat = "Flat") -> datasets
str(datasets)
# download datasets
kr <- get_datasets(datasets$FileName[7] )
readRDS(kr$IAKR7EFL) -> kr_data
kr_data
search_variable_labels(kr_data, search_terms = "diarrhea")
kr_data_var_labels
kr_data_var_labels
get_variable_labels(kr_data) -> kr_data_var_labels
kr_data_var_labels
library(wooldridge)
install.packages('wooldridge')
library(wooldridge)
data(package = 'wooldridge')
?affairs
affairs
table(affairs$naffairs)
?wooldridge
??wooldridge
help(package = 'wooldridge')
getwd()
setwd("C:/Users/Pravesh/Desktop/SANDMINING-main/SANDMINING-main/IMAGE_CLASS_R/")
library(imager)
install.packages("imager")
library(imager)
library(xgboost)
library(randomForest)
library(caret)
# Function to load and preprocess images
preprocess_image <- function(image_path, size = 64) {
img <- load.image(image_path)
img_resized <- resize(img, size, size)
as.numeric(img_resized)
}
# Function to load images from a directory
load_images_from_directory <- function(directory, size = 64) {
files <- list.files(directory, full.names = TRUE, recursive = TRUE)
labels <- gsub(".*/(YES_SANDMINING|NO_SANDMINING)/.*", "\\1", files)
data <- lapply(files, preprocess_image, size = size)
matrix(unlist(data), nrow = length(data), byrow = TRUE)
}
# Load training and test images
train_dir <- "TRAINING"
test_dir <- "TEST"
X_train <- load_images_from_directory(train_dir, size = 64)
X_test <- load_images_from_directory(test_dir, size = 64)
# Create labels
y_train <- ifelse(grepl("YES_SANDMINING", list.files(train_dir, full.names = TRUE, recursive = TRUE)), 1, 0)
y_test <- ifelse(grepl("YES_SANDMINING", list.files(test_dir, full.names = TRUE, recursive = TRUE)), 1, 0)
# Train Random Forest model
rf_model <- randomForest(X_train, as.factor(y_train), ntree = 100)
# Predict on test set
predictions <- predict(rf_model, X_test)
# Evaluate model performance
confusionMatrix(predictions, as.factor(y_test))
