---
title: "Foreclosure"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
toc: true
---

The shapefile can be downloaded from <http://www.econ.uiuc.edu/~lab/workshop/foreclosures/>

Let's load the `sf` package required to read the data. Along with it we shall also load the `tidyverse` for data maniuplation and visualisation.

```{r, warning=FALSE, message=FALSE}
library(sf)
library(tidyverse)
```

We will read the data from the working directory. We will do this by using `st_read()` from the `sf` package.

```{r}
chi <- st_read("foreclosures/foreclosures.shp")
class(chi)
```

We will now summarise the variable of interest which is the number of violent crimes reported between Jan. 2007 through December 2008 in Chicago.

```{r}
summary(chi$violent)
```

We can also visualize the crime data in a map.

```{r}
ggplot()+
  geom_sf(data = chi)+ 
  geom_sf(aes(fill = violent), 
          data = chi) +
  scale_fill_distiller(palette = 7, direction = 1)
```

The variables of interest in the dataset are

-   `est_fcs`: estimated count of foreclosure starts from Jan. 2007 through June 2008
-   `est_mtgs`: estimated number of active mortgages from Jan. 2007 through June 2008
-   `est_fcs_rt`: number of foreclosure starts divided by number of mortgages times 100
-   `bls_unemp`: June 2008 place or county unemployment rate
-   `totpop`: total population from 2000 Census
-   `violent`: number of violent crimes reported between Jan. 2007 through December 2008
-   `property`: number of property crimes reported between Jan. 2007 through December 2008

We can run a simple OLS and see that ignoring spatial dependence might lead to insignificant results.

```{r}
lm(violent ~ est_fcs_rt + bls_unemp, data = chi) -> chi_ols
summary(chi_ols)

```

## spatial dependence

-   Similar values appear close to each other, or cluster, in space (positive spatial autocorrelation or dependence) or neighboring values are dissimilar (negative spatial autocorrelation or dependence).

-   Null spatial autocorrelation indicates that the spatial pattern is random.

-   The existence of spatial autocorrelation can be determined using the following condition: $$
    Cov(y_i, y_j) \neq 0 \text{ for } i \neq j
    $$ where $y_i$ and $y_j$ are observations at random locations $i$ and $j$.

First we need to create the spatial weights matrix based on the queen criterion. We will use the `poly2nb()` function from the `spdep` package to create the neighbourhood structure and spatial weights.

```{r}
library(spdep)
poly2nb(chi) -> chi_w
summary(chi_w)
```

The output summary is for a spatial weights matrix (also known as a neighbor list) created using the `chi_w` object in R. Here's what each part of the summary means:

-   *Neighbour list object*: This indicates that the summary is for a spatial weights matrix object.
-   *Number of regions: 897*: There are 897 spatial units (e.g., polygons, points) in the dataset.
-   *Number of nonzero links: 6140*: There are 6,140 non-zero connections (links) between the spatial units. Non-zero links represent neighboring relationships.
-   *Percentage nonzero weights: 0.7631036*: Approximately 76.31% of the potential connections between spatial units are non-zero (i.e., neighbors).
-   *Average number of links: 6.845039*: On average, each spatial unit has about 6.85 neighboring units.
-   *Link number distribution*: This shows the frequency distribution of the number of links per spatial unit. For example, there is 1 spatial unit with 1 link, 5 spatial units with 2 links, and so on.
-   *1 least connected region: 866 with 1 link*: Spatial unit 866 has the fewest connections, with only 1 neighbor.
-   *2 most connected regions: 478 643 with 13 links*: Spatial units 478 and 643 have the most connections, with 13 neighbors each.

```{r}
nb2listw(chi_w)
```

## Moran Plot

-   Moran plot is used to understand the nature and strength of spatial autocorrelation.
-   It is a scatter plot where the variable of interest is plotted against its spatial lag.

```{r}
library(spdep)
moran.plot(chi$violent, listw = nb2listw(chi_w),
           pch = 20, labels = FALSE)
```

-   The diamond markers in a Moran scatter plot indicate observations that have a high influence on the linear relationship between the data and its spatially lagged values.

-   In order to be able to interpret values as above or below the mean, and their quantities in terms of standard deviations, the variable of interest is usually standardized by subtracting its mean and dividing it by its standard deviation.

```{r}
# scale() is used to standardize the variable of interest
moran.plot(as.vector(scale(chi$violent)), listw = nb2listw(chi_w),
           pch = 20, labels = FALSE)
```

-   The plot displays a positive relationship between both variables. This is associated with the presence of positive spatial autocorrelation: similar values tend to be located close to each other. This means that the overall trend is for high values to be close to other high values, and for low values to be surrounded by other low values. This however does not mean that this is only situation in the dataset: there can of course be particular cases where high values are surrounded by low ones, and viceversa. But it means that, if we had to summarize the main pattern of the data in terms of how clustered similar values are, the best way would be to say they are positively correlated and, hence, clustered over space.

## Moran's test under randomisation.

```{r}
(spdep::moran.test(chi$violent, listw = nb2listw(chi_w)) -> chi_moran)
```

The output of the Moran's I test under randomization for the variable `chi$violent` can be interpreted as follows:

1.  **Moran's I statistic standard deviate**: The observed Moran's I value standardized by its expected value and standard deviation under the null hypothesis of no spatial autocorrelation is 25.883. This is a very large value, indicating strong positive spatial autocorrelation.

2.  **p-value**: The p-value is less than 2.2e-16, which is essentially 0. This means there is overwhelming evidence to reject the null hypothesis of no spatial autocorrelation.

3.  **alternative hypothesis**: The alternative hypothesis is "greater", meaning the test is one-tailed and tests for positive spatial autocorrelation. A two-tailed test would be used to detect both positive and negative spatial autocorrelation.

4.  **Moran's I statistic**: The observed Moran's I value is 0.4728965789, indicating strong positive spatial autocorrelation. Values range from -1 to 1, with 0 indicating no spatial autocorrelation.

5.  **Expectation**: The expected value of Moran's I under the null hypothesis is -0.0011160714, which is close to the theoretical expectation of -1/(n-1) where n is the number of spatial units.

6.  **Variance**: The variance of Moran's I under the null hypothesis is 0.0003354012. This is used to standardize the Moran's I statistic.

The Moran's I test provides very strong evidence (p \< 0.0000000000000002) that the variable `chi$violent` exhibits positive spatial autocorrelation, meaning nearby areas tend to have similar values. The observed Moran's I of 0.47 is much higher than its expected value under the null hypothesis of no spatial autocorrelation.

## Moran's test under normality.

```{r}
moran.test(chi$violent, listw = nb2listw(chi_w), randomisation = FALSE)
```

## Monte Carlo simulation of Moran's I

```{r}
(moran.mc(chi$violent, listw = nb2listw(chi_w), nsim = 99) -> chi_mc)
```

In the Monte Carlo simulation of Moran's I for the variable `chi$violent`, the interpretation of the output is as follows:

1.  **Statistic**: The observed Moran's I statistic is 0.4729. This is the actual value of Moran's I calculated from the data.

2.  **Observed Rank**: The observed rank is 100. This indicates where the observed Moran's I value falls within the distribution of Moran's I values obtained from the Monte Carlo simulations.

    -   The observed rank in the Monte Carlo simulation of Moran's I refers to the position of the observed Moran's I value within the distribution of Moran's I values generated from the random permutations. Specifically, the Monte Carlo approach works as follows:

        -   The observed Moran's I value is calculated from the actual data.

        -   The values are randomly permuted among the spatial units many times (e.g., 99 or 999 times). This simulates the null hypothesis that the values are randomly distributed.

        -   For each random permutation, the Moran's I is calculated. This creates a distribution of Moran's I values under the null hypothesis.

        -   The position of the observed Moran's I value is determined within this distribution of simulated Moran's I values. This is the observed rank.

            For example, if the observed rank is 100 out of 1000 simulations, it means the observed Moran's I value is greater than 100-1 = 99 of the simulated values. This provides an empirical p-value: p-value = (number of simulated values ≥ observed) / (number of simulations + 1) So with an observed rank of 100 out of 1000 simulations, the p-value would be (100) / (1000+1) = 0.099. The observed rank is a useful way to visualize where the observed Moran's I falls relative to the distribution expected under the null hypothesis. If it falls in the extreme upper or lower tail, it provides evidence of significant spatial autocorrelation.

```{r}
plot(chi_mc)
polygon(density(chi_mc$res), col="blue")
```

-   Monte Carlo simulated values versus actual Moran’s I value. Shaded region indicates density of simulated Moran’s I versus the actual value (the vertical line).
-   The actual Moran’s I (i.e. vertical line) is far outside the simulated data (shaded range) indicating a statistically significantly relationship.

3.  **P-value**: The p-value is 0.01. This represents the probability of observing a Moran's I value as extreme as or more extreme than the observed value under the null hypothesis of no spatial autocorrelation. A p-value of 0.01 suggests that there is strong evidence to reject the null hypothesis in favor of the alternative hypothesis.

4.  **Alternative Hypothesis**: The alternative hypothesis is "greater", indicating that the test is one-tailed and specifically looking for positive spatial autocorrelation.

With a p-value of 0.01, there is strong evidence to suggest that the variable `chi$violent` exhibits significant positive spatial autocorrelation. The observed Moran's I value of 0.4729 falls in the top 1% of the distribution of Moran's I values obtained from the Monte Carlo simulations, supporting the presence of spatial clustering in the data.

*Randomization is specifically focused on testing the significance of observed patterns against random chance, while Monte Carlo simulation is a broader technique used for modeling and estimating outcomes by generating random samples or scenarios. In spatial analysis, both methods play important roles in assessing spatial patterns and relationships.*

------------------------------------------------------------------------

## Local indicators

```{r, echo=FALSE}
library(RColorBrewer)
match_palette <- function(patterns, classifications, colors){
  classes_present <- base::unique(patterns)
  mat <- matrix(c(classifications,colors), ncol = 2)
  logi <- classifications %in% classes_present
  pre_col <- matrix(mat[logi], ncol = 2)
  pal <- pre_col[,2]
  return(pal)
}

lisa_map <- function(df, lisa, alpha = .05) {
  clusters <- lisa_clusters(lisa,cutoff = alpha)
  labels <- lisa_labels(lisa)
  pvalue <- lisa_pvalues(lisa)
  colors <- lisa_colors(lisa)
  lisa_patterns <- labels[clusters+1]

  pal <- match_palette(lisa_patterns,labels,colors)
  labels <- labels[labels %in% lisa_patterns]

  df["lisa_clusters"] <- clusters
  tm_shape(df) +
    tm_fill("lisa_clusters",labels = labels, palette = pal,style = "cat")
}

significance_map <- function(df, lisa, permutations = 999, alpha = .05) {
  pvalue <- lisa_pvalues(lisa)
  target_p <- 1 / (1 + permutations)
  potential_brks <- c(.00001, .0001, .001, .01)
  brks <- potential_brks[which(potential_brks > target_p & potential_brks < alpha)]
  brks2 <- c(target_p, brks, alpha)
  labels <- c(as.character(brks2), "Not Significant")
  brks3 <- c(0, brks2, 1)
  
  cuts <- cut(pvalue, breaks = brks3,labels = labels)
  df["sig"] <- cuts
  
  pal <- rev(brewer.pal(length(labels), "Greens"))
  pal[length(pal)] <- "#D3D3D3"
  
  tm_shape(df) +
    tm_fill("sig", palette = pal)
}
```

-   We will calculate the local Moran's I and create cluster maps.

-   Significance Maps:

    -   LISA significance maps evaluate the statistical significance of spatial patterns in the data.
    -   These maps assess the significance level at which each region contributes to the global spatial autocorrelation outcome.
    -   Significance is determined through a Monte Carlo randomization procedure, comparing actual LISA values to values obtained by random data reassignments.
    -   Actual LISA values are ranked relative to values produced by randomization, with top-ranked values considered statistically significant at specific levels (e.g., 0.001, 0.01, 0.05).
    -   Statistically significant results can be either very high or very low, indicating spatial clusters or outliers.
    -   LISA cluster maps help visualize spatial clusters of similar or dissimilar values, highlighting areas with significant spatial patterns.
    -   Significance maps provide insights into the statistical significance of these spatial patterns, identifying areas contributing strongly to global spatial autocorrelation.
    -   By combining LISA cluster maps and significance maps, analysts can understand which locations contribute most to the overall spatial pattern and in which direction.

```{r}
library(rgeoda)
library(tmap)

# calculate the local Moran's I
local_moran(w = queen_weights(chi), df = chi[,"violent"]) -> chi_local_moran

# Plot the cluster map
lisa_map(chi, chi_local_moran) + 
  tm_borders()

# Plot the significane map
significance_map(chi, chi_local_moran)+
  tm_borders()
```

-   We can also create interactive maps

```{r}
tmap_mode("view")

lisa_map(chi, chi_local_moran) + 
  tm_borders()+
  tm_layout(title = "Local Moran Cluster Map of Violent Crimes",legend.outside = TRUE)
tmap_mode("plot")
```

## Permutations

-   To obtain higher significance levels, we need to use more permutations in the computation of the the local moran for each location. For instance, a pseudo pvalue of .00001 would require 999999 permutations. To get more permutations, we set permutations = 99999 in local_moran. It is important to note that the maximum number of permutations for this function is 99999.

```{r}
# compute the local moran using permutations
local_moran(w = queen_weights(chi),
            df = chi[,"violent"],
            permutations = 9999) -> chi_local_moran_permu 

# plot the cluster map
lisa_map(chi, chi_local_moran_permu) +
  tm_borders()

```

## Conditioal local cluster maps

```{r}
chi$cut_bls_unemp <- cut(chi$bls_unemp, breaks = 2)

lisa_map(chi, chi_local_moran) +
  tm_borders()+
  tm_facets(by = "cut_bls_unemp",
            free.coords = FALSE,
            drop.units = FALSE)
```


## Local Geary
- It differs from the other global counterparts in that it uses squared differences rather than dissimilarity.
- The Local Geary Statitic is:
  $$LG_i = \Sigma_jw_{ij}(x_i-x_j)^2$$
- The inference and interpretation is the same as that of the Local Moran statistic.
- The locations with the Locl Geary statistic smaller than its mean can be identified as significant and having positive spatial autocorrelation. 

```{r}
# Calculate the local Geary

local_geary(w = queen_weights(chi), chi[, "violent"]) -> chi_local_geary

# Plot the cluster map
lisa_map(chi, chi_local_geary)+
  tm_borders()

# Plot the significance map
significance_map(chi, chi_local_geary) +
  tm_borders()+
  tm_layout("Loal Geary Significance Map", legend.outside = TRUE)
```

## Getis-Ord Statistic

- This is also a local measure of spatial autocorrelation.
- It is a ratio of the number of observations within a given range to the total count of points.
- The Getis-Ord $G_i^*$ statistic has two versions that differ in whether they include the value at the given location when calculating the statistic:
  1. **Gi statistic**:
   - The Gi statistic consists of a ratio of the weighted average of the values in the neighboring locations to the sum of all values, excluding the value at the location ($x_i$).
   - It is calculated as: $$G_i = \frac{\sum_{j \neq i} w_{ij} x_j}{\sum_{j \neq i} x_j}$$

  2. **$G_i^*$ statistic**:
   - The $G_i^*$ statistic includes the value $x_i$ in both the numerator and denominator.
   - It is calculated as: $$G_i^* = \frac{\sum_j w_{ij} x_j}{\sum_j x_j}$$
   - In this case, the denominator is constant across all observations and simply consists of the total sum of all values in the dataset.

- The $G_i^*$ statistic is the ratio of the average values in a window centered on an observation to the total sum of observations. It does not consider spatial outliers, unlike statistics like Local Moran's I.

- The interpretation of both Getis-Ord statistics is straightforward:

  - A value larger than the mean (or a positive z-value) suggests a High-High cluster or hot spot.
  - A value smaller than the mean (or a negative z-value) indicates a Low-Low cluster or cold spot.

**What is the significance and implications of G and G* statistics in terms of their difference in not considering the value at the location x_i?**

- The significance and implications of the G and G* statistics in terms of their difference in not considering the value at the location $x_i$ are as follows:
    - G Statistic:
    - The G statistic does not include the value at the given location $x_i$ when calculating the ratio of the weighted average of values in neighboring locations to the sum of all values, excluding the value at the location $x_i$.
    - This exclusion of the value at the location allows the G statistic to focus solely on the relationship between neighboring values without the influence of the value at the specific location being analyzed.
    - The G statistic provides insights into the spatial clustering of values based on neighboring observations, highlighting local spatial patterns without the direct impact of the value at the location of interest.

    - $G*$ Statistic:
    - In contrast, the G* statistic includes the value at the given location $x_i$ in both the numerator and denominator when calculating the ratio of the weighted average of values in neighboring locations to the sum of all values.
    - By including the value at the location, the G* statistic provides a more comprehensive view of the spatial relationship between the value at the location and its neighbors, offering insights into the overall spatial clustering pattern that incorporates the specific location's value
    - The G* statistic allows for a more holistic analysis of local spatial autocorrelation, considering the value at the location alongside neighboring values to assess the clustering of values in a spatial context

**What is the significance of not considering the outlier in the Getis-Ord statistic as compared to the Morans I?**

- The significance of not considering outliers in the Getis-Ord statistic compared to Moran's I lies in the focused analysis of spatial clustering without the influence of extreme values. While Moran's I provides a more comprehensive view by considering both clusters and outliers, the Getis-Ord statistic is specifically tailored for hotspot analysis and identifying statistically significant spatial patterns without the interference of outliers.

- Implementing the G statistic.

```{r}
# Calculate the G statistic
rgeoda::local_g(w = queen_weights(chi), chi[, "violent"]) -> chi_local_g

# cluster map
lisa_map(chi, chi_local_g) +
  tm_borders()

# Significance map
significance_map(chi, chi_local_g)+
  tm_borders()

```

- Implementing the G* statistic.

```{r}
# Calculate the G statistic
rgeoda::local_gstar(w = queen_weights(chi), chi[, "violent"]) -> chi_local_gstar

# cluster map
lisa_map(chi, chi_local_gstar) +
  tm_borders()

# Significance map
significance_map(chi, chi_local_gstar)+
  tm_borders()

```

**Interpretation of the cluster map:** 

- Look for areas with similar values that cluster together (High-High or Low-Low clusters) or areas with contrasting values that cluster (High-Low or Low-High clusters) in the maps.

**Interpretation of the Significance maps:**

- Identify areas with significant positive spatial autocorrelation (hot spots) or negative spatial autocorrelation (cold spots) based on the p-values and z-scores in the maps.

- Increasing permutations gives us more detailed information about the significance at each location.
- The level of significance 

```{r}
# cluster map with alpha = 0.01 
lisa_map(chi, chi_local_gstar, alpha = 0.01) +
  tm_borders()

# Significance map
significance_map(chi, chi_local_gstar, permutations = 9999, alpha = 0.01)+
  tm_borders()

```

## Linear regression and diagnostics for spatial dependence

- Standard linear regression assumes independent errors.
- A standard linear regression model in the matrix form
$$
Y_{\{n\times 1\}} = X_{\{n \times p\}}\beta_{\{p \times 1\}}  + \epsilon_{\{n \times 1\}}
$$
  where, $\epsilon$ is independently and identically and Normally distributed with zero mean and constant variance.
  
- $\beta$ can be estimated using OLS.
- The model is linear in coefficients (i.e. the regression coefficients enter the model linearly via addition, subtraction or multiplication, but not division, exponentiation, or other non-linear forms).

- If the errors are spatially dependent the OLS estimate of $\beta$ will no longer be efficient (although it  will be normal and unbiased).
- Distinct patterns in residuals may suggest departures from model assumptions and indicate nonlinearlty, unequal variances and non-normality.

- Unequal variances, or heteroscedasticity, can be revealed with tests such as the Breusch-Pagan test (Breusch & Pagan, 1979) or the Koenker-Bassett test (Koenker & Bassett, 1982).
- Nonnormality can be revealed using tests such as the Jarque-Bera test (Bera & Jarque, 1980), which has an asymptotic chi-squared distribution with two degrees of freedom

## Diagnostics for spatial dependence

- If there is clear evidence of spatial dependence, standard linear regression fitting may no longer be appropriate.
- Tools for diagnosing spatial dependence, particularly spatial autocorrelation, include Moran’s I plot and Moran’s I statistic of the residuals.
- The appropriateness of a spatial regression model with respect to spatial lag dependence and spatial error dependence can be partly indicated by
• the Lagrange multiplier (LM) test (Bera & Yoon, 1993) and
• the robust LM test.
The LM test statistic follows a chi-squared distribution with one degree of freedom under the null hypothesis of no spatial dependence and can be used to reveal spatial dependence in the form of an omitted spatially lagged dependent variable and/or spatial error dependence (Anselin, 1988a). 
- When the lag dependence and error dependence are both found to be statistically significant using the LM test, a robust LM test can reveal further spatial dependence (Baltagi & Yang, 2013). The robust/adjusted LM test can be used to diagnose spatial lag dependence in the presence of spatial error dependence and to diagnose spatial error dependence in the presence of a spatially lagged dependent variable (Anselin, Bera, Florax, & Yoon, 1996). MLE can be used to estimate the parameters in the appropriate spatial regression model indicated by the robust LM test.

```{r}
# The LM test spatial lag
spdep::lm.RStests(chi_ols, listw = nb2listw(chi_w),
                  test = "RSlag")
```

- The output provided is from the Rao's score (a.k.a Lagrange multiplier) diagnostics for spatial dependence. Here is the interpretation of the results:

    `RSlag`: This value, 182.18, represents the Rao's score for the spatial lag in the spatial dependence model.
    `df`: The degrees of freedom associated with the Rao's score test is 1.
   `p-value`: The p-value associated with the Rao's score test is less than 2.2e-16, indicating strong statistical significance.

Interpretation:

  - The significant `p-value` (< 2.2e-16) suggests strong evidence of spatial dependence in the model.
  - The Rao's score (LM) test has detected spatial autocorrelation in the the model, indicating that the errors are not spatially independent.
  - This result implies that there is a spatial structure in the residuals that is not explained by the variables in the model, highlighting the presence of spatial autocorrelation that needs to be accounted for in the analysis.
  

- When you set test = "adjRSlag" in the RStests() function, it computes the adjusted Lagrange multiplier test for spatial dependence, considering the possible absence of a lagged dependent variable in the model. This adjusted test helps account for any missing spatially lagged dependent variable and provides a more robust assessment of spatial dependence in the linear model.

```{r}
# The LM test spatial lag
spdep::lm.RStests(chi_ols, listw = nb2listw(chi_w),
                  test = "adjRSlag")
```

- If the errors are diagnosed to be spatially dependent, a common remedial measure is to expand the *standard linear regression models* to *spatial linear regression models*.
- Most of these spatial regression models consider spatial lag dependence and/or spatial error dependence, two basic types of spatial dependence.

- A spatial linear regression model can be considered a generalization of a standard linear regression model in that spatial models allow and explicitly account for spatial dependence in the error term. 
- The usual regression coefficients of the explanatory variables $\beta$ and the variance of the error term $\sigma^2$ are the model parameters. 
- The spatial regression models that are most commonly used also have a spatial dependence parameter $\rho$ measuring the strength of the spatial dependence. 
- Both a variance weight matrix ($D$) and a spatial weight matrix ($W$) corresponding to a neighborhood structure are specified before the model is fitted. 

## Spatial Lag Model
- The mathematical meaning of the term "lagged" in the context of spatial analysis and statistics refers to a value or observation that is shifted in time or space relative to another value or observation.
- For example, in calculating Moran's I, the lagged value of a variable at a given location is the value of the same variable at a neighboring location. The spatial autocorrelation statistic is then calculated based on the similarity or dissimilarity between the original values and their lagged counterparts.
- A spatial lag model is specified as:

$$
Y_{\{n\times 1\}} = X_{\{n \times p\}}\beta_{\{p \times 1\}} + \rho WY + \epsilon_{\{n \times 1\}}
$$
  where, $\rho$ is a scalar spatial lag parameter.
  $W$ is a $n \times n$ spatial weight matrix
  
- $WY$ denotes a spatially lagged variable because it is a weighted average of the neighbourhood response variables.

- When $\rho = 0$ the spatial lag model is reduced to the standard linear regression model.
- The spatial lag model builds a relation between *the response variable in an areal unit* with *a weighted average of the response variable at the neighbouring areal units*.

## Model fitting

- OLS is limited in case of Spatial lag models because it does not directly account for spatial dependence in data.
- The Maximum Likelihood Estimation (MLE) is appropriate.
- MLE selects the set of parameter estimates (the coefficients and spatial parameters) that results in the maximum likelihood (i.e., the largest probability) of the observed data .
- Intuitively, there could be an infinite number of combinations of the parameters, and each set results in a likelihood value. 
- Among all the likelihood values, we want the parameters that make the data most probable with the highest likelihood. The resulting parameters are called maximum likelihood estimates.

- In the likelihood inference framework, the often-used measures of the goodness of the model fit include maximum log-likelihood value, Akaike’s information criterion (AIC) (Akaike, 1973), and Schwartz’s Bayesian
information criterion (BIC) (Schwartz, 1978). 
- Nested models (simpler models reduced from another more complex model after constraining certain parameters in the complex model) can be compared by a likelihood ratio test (LRT). 
- For nonnested models, AIC and BIC are often used; they measure the model fitting to the data but penalize overly complex models. 
- Models having a smaller AIC or a smaller BIC are considered the
better models in the sense of model fitting balanced with model parsimony.

```{r}
library(spatialreg)
# MLE of spatial autoregressive models
lagsarlm(violent ~ est_fcs_rt + bls_unemp, 
         data = chi,
         listw = nb2listw(chi_w), zero.policy = TRUE) %>% summary() 

```

>When zero.policy = TRUE, if a zone has no neighbors, the lagged value for that zone is assigned a value of zero. This is done to avoid missing values (NA) in the spatial weights matrix. For example, if you have a spatial weights matrix listw and a data vector x, and some zones in x have no neighbors, then:
  - If `zero.policy = TRUE`, the lagged value for those zones without neighbors will be set to zero.
  - If `zero.policy = FALSE` (the default), the lagged value for those zones without neighbors will be set to NA.
Setting `zero.policy = TRUE` allows the analysis to proceed without errors due to missing values, but it may impact the results if the zones without neighbors are not truly zeros.

The output provided is from the spatial lag model (SLM) fitted using the `lagsarlm()` function from the `spatialreg` package in R. Here is the interpretation of the results:

  `Residuals`: The minimum, first quartile, median, third quartile, and maximum values of the residuals are reported. These residuals are from the spatial lag model.
  `Type`: The type of spatial model fitted is a lag model, which means that a spatially lagged dependent variable is included as an explanatory variable.
   `Coefficients`:
        The intercept is -93.7885, with a standard error of 41.3162.
        The coefficient for `est_fcs_rt` is 15.6822, with a standard error of 1.5600. This variable is highly significant (p-value < 2e-16).
        The coefficient for `bls_unemp` is 8.8949, with a standard error of 5.2447. This variable is marginally significant (p-value = 0.08989).
    `Rho (ρ)`: The estimate of the spatial autoregressive parameter (ρ) is 0.49037. This indicates a moderate degree of spatial autocorrelation in the dependent variable.
    The p-value for the spatial autoregressive parameter (ρ) is reported as < 2.22e-16, which is extremely small and indicates very strong statistical significance. This means that the null hypothesis of `ρ = 0 `(no spatial autocorrelation) can be rejected at any reasonable significance level. The spatial lag term is highly significant in the model, confirming that there is a substantial degree of spatial dependence in the dependent variable. The very low p-value, along with the moderate estimate of ρ (0.49037), provides strong evidence that the dependent variable exhibits a moderate degree of positive spatial autocorrelation. This spatial dependence is appropriately captured by including the spatially lagged dependent variable (Wy) as an explanatory variable in the spatial lag model
    `Likelihood Ratio (LR) Test`: The LR test value is 141.33, with a p-value < 2.22e-16. This test compares the spatial lag model to the non-spatial linear model. The highly significant p-value suggests that the spatial lag model provides a significantly better fit to the data.
    `Wald Test`: The Wald statistic is 153.93, with a p-value < 2.22e-16. This test also assesses the significance of the spatial autoregressive parameter (ρ). The highly significant p-value confirms the importance of including the spatially lagged dependent variable in the model.
    `Log Likelihood`: The log-likelihood value for the spatial lag model is -5738.047.
    R`esidual Variance`: The maximum likelihood estimate of the residual variance (σ²) is 20200, with a standard deviation (σ) of 142.13.
    `Model Information`: The number of observations is 897, and the number of parameters estimated is 5. The Akaike Information Criterion (AIC) for the spatial lag model is 11486, which is lower than the AIC for the non-spatial linear model (11625), indicating a better fit.
   ` Moran's I Test`: The LM test for residual autocorrelation has a test value of 8.1464 and a p-value of 0.0043146. This suggests that there is still some residual spatial autocorrelation not accounted for by the spatial lag model.


## References

-   <https://swampthingecology.org/blog/hot-spot-analysis-geospatial-data-analysis-in-rstats.-part-3/>
-   <https://spatialanalysis.github.io/handsonspatialdata/local-spatial-autocorrelation-1.html>
-   <http://darribas.org/gds19/content/labs/lab_06.html>
-   <Spatial_Econometrics_with_R_2020>(Spatial_Econometrics_with_R_2020.pdf)
